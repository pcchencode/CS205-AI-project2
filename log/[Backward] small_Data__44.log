Welcome to Po-Chu Feature Selection Algorithm.
Type in the name of the file to test: CS205_small_Data__44.txt

Type the number of the algorithm you want to run.
1) Forward Selection
2) Backward Elimination
2

This dataset has 12 features (not including the class attribute), with 500 instances.

Running nearest neighbor with all 12 features, using "leaving-one-out" evaluation, I get an accuracy of 75.2%
Calculating initial global best accuracy
Global best accuracy using all 50 features is 0.752
Beginning search.

    Using feature(s) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  75.4%
    Using feature(s) [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  75.6%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  76.4%
    Using feature(s) [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  76.2%
    Using feature(s) [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12] accuracy is  75.4%
    Using feature(s) [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12] accuracy is  74.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12] accuracy is  75.4%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] accuracy is  71.4%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12] accuracy is  76.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12] accuracy is  73.4%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12] accuracy is  75.8%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  77.6%

Feature set [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] was best, accuracy is  77.6%

    Using feature(s) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  78.0%
    Using feature(s) [1, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  75.6%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  79.0%
    Using feature(s) [1, 2, 3, 5, 6, 7, 8, 9, 10, 11] accuracy is  76.8%
    Using feature(s) [1, 2, 3, 4, 6, 7, 8, 9, 10, 11] accuracy is  78.4%
    Using feature(s) [1, 2, 3, 4, 5, 7, 8, 9, 10, 11] accuracy is  75.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 8, 9, 10, 11] accuracy is  76.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10, 11] accuracy is  72.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10, 11] accuracy is  78.4%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11] accuracy is  73.6%
    Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] accuracy is  76.0%

Feature set [1, 2, 4, 5, 6, 7, 8, 9, 10, 11] was best, accuracy is  79.0%

    Using feature(s) [2, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  78.4%
    Using feature(s) [1, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  78.8%
    Using feature(s) [1, 2, 5, 6, 7, 8, 9, 10, 11] accuracy is  79.2%
    Using feature(s) [1, 2, 4, 6, 7, 8, 9, 10, 11] accuracy is  78.2%
    Using feature(s) [1, 2, 4, 5, 7, 8, 9, 10, 11] accuracy is  79.4%
    Using feature(s) [1, 2, 4, 5, 6, 8, 9, 10, 11] accuracy is  80.4%
    Using feature(s) [1, 2, 4, 5, 6, 7, 9, 10, 11] accuracy is  74.2%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 10, 11] accuracy is  81.2%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 11] accuracy is  74.8%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10] accuracy is  78.0%

Feature set [1, 2, 4, 5, 6, 7, 8, 10, 11] was best, accuracy is  81.2%

    Using feature(s) [2, 4, 5, 6, 7, 8, 10, 11] accuracy is  81.2%
    Using feature(s) [1, 4, 5, 6, 7, 8, 10, 11] accuracy is  78.4%
    Using feature(s) [1, 2, 5, 6, 7, 8, 10, 11] accuracy is  78.8%
    Using feature(s) [1, 2, 4, 6, 7, 8, 10, 11] accuracy is  82.2%
    Using feature(s) [1, 2, 4, 5, 7, 8, 10, 11] accuracy is  82.8%
    Using feature(s) [1, 2, 4, 5, 6, 8, 10, 11] accuracy is  81.6%
    Using feature(s) [1, 2, 4, 5, 6, 7, 10, 11] accuracy is  69.8%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 11] accuracy is  78.2%
    Using feature(s) [1, 2, 4, 5, 6, 7, 8, 10] accuracy is  82.2%

Feature set [1, 2, 4, 5, 7, 8, 10, 11] was best, accuracy is  82.8%

    Using feature(s) [2, 4, 5, 7, 8, 10, 11] accuracy is  82.6%
    Using feature(s) [1, 4, 5, 7, 8, 10, 11] accuracy is  82.2%
    Using feature(s) [1, 2, 5, 7, 8, 10, 11] accuracy is  83.2%
    Using feature(s) [1, 2, 4, 7, 8, 10, 11] accuracy is  84.8%
    Using feature(s) [1, 2, 4, 5, 8, 10, 11] accuracy is  83.6%
    Using feature(s) [1, 2, 4, 5, 7, 10, 11] accuracy is  73.0%
    Using feature(s) [1, 2, 4, 5, 7, 8, 11] accuracy is  77.8%
    Using feature(s) [1, 2, 4, 5, 7, 8, 10] accuracy is  83.2%

Feature set [1, 2, 4, 7, 8, 10, 11] was best, accuracy is  84.8%

    Using feature(s) [2, 4, 7, 8, 10, 11] accuracy is  83.4%
    Using feature(s) [1, 4, 7, 8, 10, 11] accuracy is  83.2%
    Using feature(s) [1, 2, 7, 8, 10, 11] accuracy is  86.8%
    Using feature(s) [1, 2, 4, 8, 10, 11] accuracy is  86.6%
    Using feature(s) [1, 2, 4, 7, 10, 11] accuracy is  72.0%
    Using feature(s) [1, 2, 4, 7, 8, 11] accuracy is  80.4%
    Using feature(s) [1, 2, 4, 7, 8, 10] accuracy is  86.6%

Feature set [1, 2, 7, 8, 10, 11] was best, accuracy is  86.8%

    Using feature(s) [2, 7, 8, 10, 11] accuracy is  86.2%
    Using feature(s) [1, 7, 8, 10, 11] accuracy is  87.6%
    Using feature(s) [1, 2, 8, 10, 11] accuracy is  89.8%
    Using feature(s) [1, 2, 7, 10, 11] accuracy is  72.4%
    Using feature(s) [1, 2, 7, 8, 11] accuracy is  81.6%
    Using feature(s) [1, 2, 7, 8, 10] accuracy is  88.4%

Feature set [1, 2, 8, 10, 11] was best, accuracy is  89.8%

    Using feature(s) [2, 8, 10, 11] accuracy is  88.6%
    Using feature(s) [1, 8, 10, 11] accuracy is  88.6%
    Using feature(s) [1, 2, 10, 11] accuracy is  73.4%
    Using feature(s) [1, 2, 8, 11] accuracy is  83.6%
    Using feature(s) [1, 2, 8, 10] accuracy is  90.2%

Feature set [1, 2, 8, 10] was best, accuracy is  90.2%

    Using feature(s) [2, 8, 10] accuracy is  91.4%
    Using feature(s) [1, 8, 10] accuracy is  93.2%
    Using feature(s) [1, 2, 10] accuracy is  70.8%
    Using feature(s) [1, 2, 8] accuracy is  86.2%

Feature set [1, 8, 10] was best, accuracy is  93.2%

    Using feature(s) [8, 10] accuracy is  93.2%
    Using feature(s) [1, 10] accuracy is  72.4%
    Using feature(s) [1, 8] accuracy is  89.0%

Feature set [8, 10] was best, accuracy is  93.2%

    Using feature(s) [10] accuracy is  69.8%
    Using feature(s) [8] accuracy is  88.8%

(WARNING, Accuracy has decreased! Continuing search in case of local maximum)
Feature set [8] was best, accuracy is  88.8%

Finished search!! The best feature subset is [8, 10], which has accuracy of  93.2%
backward_elimination cost time: 32.711 s